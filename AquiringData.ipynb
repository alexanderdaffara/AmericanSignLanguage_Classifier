{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv('data/train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(signs):\n",
    "    !echo \"\" > 'junk_out'\n",
    "    old_sign = ''\n",
    "    old_pid = None\n",
    "    for i, sign in enumerate(signs):\n",
    "        for participant_id in y.participant_id.unique():\n",
    "            y_subset = y.loc[(y.sign == sign) & (y.participant_id == participant_id)]\n",
    "            data = []\n",
    "            for path in y_subset.path:\n",
    "                pid_dir = '/'.join(path.split('/')[:-1])\n",
    "                old_path_to_parquet = \"zip_dir/\" + path.split('/')[-1]\n",
    "                path_to_zip_file = old_path_to_parquet + \".zip\"\n",
    "                !kaggle competitions download -c asl-signs -f $path -p 'zip_dir'\n",
    "                !unzip -n -qq $path_to_zip_file -d 'zip_dir' 2>> junk_out\n",
    "                !mv $old_path_to_parquet $path 2>> junk_out\n",
    "                !rm $path_to_zip_file\n",
    "\n",
    "def release_data():\n",
    "    !find zip_dir -type f -delete\n",
    "    !find train_landmark_files -type f -delete\n",
    "\n",
    "def update_dataset(dataset, signs, col_names):\n",
    "\n",
    "    for i, sign in enumerate(signs):\n",
    "        print(f'sign: {sign}, {i+1}/{len(signs)}')\n",
    "        for j, participant_id in enumerate(y.participant_id.unique()):\n",
    "            print(f'    pid: {j+1}/21')\n",
    "            participant_id = 26734\n",
    "            y_subset = y.loc[(y.sign == sign) & (y.participant_id == participant_id)]\n",
    "            data = []\n",
    "            for path in y_subset.path:\n",
    "                df = pd.read_parquet(path)\n",
    "                this_data = []\n",
    "                for type in set(df.type):\n",
    "                    df_t = df.loc[df.type == type]\n",
    "                    for lm_i in set(df_t.landmark_index):\n",
    "                        df_t_i = df_t.loc[(df_t['x'].notna()) & (df_t['y'].notna()) & (df_t.landmark_index == lm_i)]\n",
    "                        if df_t_i.shape[0] != 0:\n",
    "                            this_data.append(df_t_i.iloc[0]['x'])\n",
    "                            this_data.append(df_t_i.iloc[0]['y'])\n",
    "                            this_data.append(df_t_i.iloc[-1]['x'] - df_t_i.iloc[0]['x'])\n",
    "                            this_data.append(df_t_i.iloc[-1]['y'] - df_t_i.iloc[0]['y'])\n",
    "                        else:\n",
    "                            this_data.extend([0,0,0,0])\n",
    "                data.append(this_data + [sign])\n",
    "            sign_df = pd.DataFrame(data, columns=col_names + ['sign'])\n",
    "            pd.concat((dataset,sign_df), axis=0)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "User cancelled operation\n",
      "rm: zip_dir/1000035562.parquet.zip: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "col_names = pd.read_csv('data/col_names.csv', index_col=0)['0']\n",
    "dataset = pd.DataFrame([],columns=col_names)\n",
    "\n",
    "signs = ['blow','drink','donkey','finish','up']\n",
    "\n",
    "download_data(signs)\n",
    "dataset = update_dataset(dataset,signs,col_names)\n",
    "release_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
