{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_landmark_files/26734/1000035562.parquet</td>\n",
       "      <td>26734</td>\n",
       "      <td>1000035562</td>\n",
       "      <td>blow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_landmark_files/28656/1000106739.parquet</td>\n",
       "      <td>28656</td>\n",
       "      <td>1000106739</td>\n",
       "      <td>wait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_landmark_files/16069/100015657.parquet</td>\n",
       "      <td>16069</td>\n",
       "      <td>100015657</td>\n",
       "      <td>cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_landmark_files/25571/1000210073.parquet</td>\n",
       "      <td>25571</td>\n",
       "      <td>1000210073</td>\n",
       "      <td>bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_landmark_files/62590/1000240708.parquet</td>\n",
       "      <td>62590</td>\n",
       "      <td>1000240708</td>\n",
       "      <td>owie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94472</th>\n",
       "      <td>train_landmark_files/53618/999786174.parquet</td>\n",
       "      <td>53618</td>\n",
       "      <td>999786174</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94473</th>\n",
       "      <td>train_landmark_files/26734/999799849.parquet</td>\n",
       "      <td>26734</td>\n",
       "      <td>999799849</td>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94474</th>\n",
       "      <td>train_landmark_files/25571/999833418.parquet</td>\n",
       "      <td>25571</td>\n",
       "      <td>999833418</td>\n",
       "      <td>flower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94475</th>\n",
       "      <td>train_landmark_files/29302/999895257.parquet</td>\n",
       "      <td>29302</td>\n",
       "      <td>999895257</td>\n",
       "      <td>room</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94476</th>\n",
       "      <td>train_landmark_files/36257/999962374.parquet</td>\n",
       "      <td>36257</td>\n",
       "      <td>999962374</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94477 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  participant_id  \\\n",
       "0      train_landmark_files/26734/1000035562.parquet           26734   \n",
       "1      train_landmark_files/28656/1000106739.parquet           28656   \n",
       "2       train_landmark_files/16069/100015657.parquet           16069   \n",
       "3      train_landmark_files/25571/1000210073.parquet           25571   \n",
       "4      train_landmark_files/62590/1000240708.parquet           62590   \n",
       "...                                              ...             ...   \n",
       "94472   train_landmark_files/53618/999786174.parquet           53618   \n",
       "94473   train_landmark_files/26734/999799849.parquet           26734   \n",
       "94474   train_landmark_files/25571/999833418.parquet           25571   \n",
       "94475   train_landmark_files/29302/999895257.parquet           29302   \n",
       "94476   train_landmark_files/36257/999962374.parquet           36257   \n",
       "\n",
       "       sequence_id    sign  \n",
       "0       1000035562    blow  \n",
       "1       1000106739    wait  \n",
       "2        100015657   cloud  \n",
       "3       1000210073    bird  \n",
       "4       1000240708    owie  \n",
       "...            ...     ...  \n",
       "94472    999786174   white  \n",
       "94473    999799849    have  \n",
       "94474    999833418  flower  \n",
       "94475    999895257    room  \n",
       "94476    999962374   happy  \n",
       "\n",
       "[94477 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.read_csv('data/train.csv')\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dataset(dataset, signs, col_names):\n",
    "    print(f'recordings found: {y.loc[[s in signs for s in y.sign]].shape[0]}')\n",
    "    for i, sign in enumerate(signs):\n",
    "        print(f'sign: {sign}, {i+1}/{len(signs)}')\n",
    "        for j, participant_id in enumerate(y.participant_id.unique()):\n",
    "            print(f'    pid: {j+1}/21')\n",
    "            y_subset = y.loc[(y.sign == sign) & (y.participant_id == participant_id)]\n",
    "            data = []\n",
    "            n = y_subset.shape[0]\n",
    "            for k, path in enumerate(y_subset.path):\n",
    "                print(f'        recording: {k+1}/{n}')\n",
    "                path_D = \"D:/\" + path\n",
    "                df = pd.read_parquet(path_D)\n",
    "                this_data = []\n",
    "                for type in set(df.type):\n",
    "                    df_t = df.loc[df.type == type]\n",
    "                    for lm_i in set(df_t.landmark_index):\n",
    "                        df_t_i = df_t.loc[(df_t['x'].notna()) & (df_t['y'].notna()) & (df_t.landmark_index == lm_i)]\n",
    "                        if df_t_i.shape[0] != 0:\n",
    "                            this_data.append(df_t_i.iloc[0]['x'])\n",
    "                            this_data.append(df_t_i.iloc[0]['y'])\n",
    "                            this_data.append(df_t_i.iloc[-1]['x'] - df_t_i.iloc[0]['x'])\n",
    "                            this_data.append(df_t_i.iloc[-1]['y'] - df_t_i.iloc[0]['y'])\n",
    "                        else:\n",
    "                            this_data.extend([0,0,0,0])\n",
    "                data.append(this_data + [sign])\n",
    "            sign_df = pd.DataFrame(data, columns=col_names)\n",
    "            dataset = pd.concat((dataset,sign_df), axis=0, ignore_index=True)\n",
    "    return dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Signs used on round two of data collection\n",
    "['pig',\n",
    " 'elephant',\n",
    " 'mad',\n",
    " 'finger',\n",
    " 'green',\n",
    " 'up',\n",
    " 'bad',\n",
    " 'finger',\n",
    " 'bye',\n",
    " 'airplane',\n",
    " 'mom',\n",
    " 'kitty',\n",
    " 'home',\n",
    " 'yellow',\n",
    " 'shirt',\n",
    " 'talk',\n",
    " 'icecream',\n",
    " 'green',\n",
    " 'clown',\n",
    " 'lion',\n",
    " 'bad',\n",
    " 'thirsty',\n",
    " 'elephant',\n",
    " 'book',\n",
    " 'shirt',\n",
    " 'dog',\n",
    " 'finger',\n",
    " 'pretty',\n",
    " 'vacuum',\n",
    " 'vacuum',\n",
    " 'chocolate',\n",
    " 'pretty',\n",
    " 'same',\n",
    " 'red',\n",
    " 'every',\n",
    " 'feet',\n",
    " 'drawer',\n",
    " 'gum',\n",
    " 'drop',\n",
    " 'story',\n",
    " 'puppy',\n",
    " 'haveto',\n",
    " 'book',\n",
    " 'bad',\n",
    " 'zebra',\n",
    " 'cat',\n",
    " 'cow',\n",
    " 'mad',\n",
    " 'dryer',\n",
    " 'old',\n",
    " 'clown',\n",
    " 'garbage',\n",
    " 'stairs',\n",
    " 'cute',\n",
    " 'wolf',\n",
    " 'for',\n",
    " 'tree',\n",
    " 'stairs',\n",
    " 'sick',\n",
    " 'finish',\n",
    " 'bird',\n",
    " 'nose',\n",
    " 'no',\n",
    " 'drop',\n",
    " 'yellow',\n",
    " 'garbage',\n",
    " 'have',\n",
    " 'blow',\n",
    " 'wet',\n",
    " 'airplane',\n",
    " 'vacuum',\n",
    " 'no',\n",
    " 'bye',\n",
    " 'nose',\n",
    " 'give',\n",
    " 'puppy',\n",
    " 'gum',\n",
    " 'dry',\n",
    " 'shower',\n",
    " 'another',\n",
    " 'every',\n",
    " 'haveto',\n",
    " 'wolf',\n",
    " 'bee',\n",
    " 'empty',\n",
    " 'puppy',\n",
    " 'thirsty',\n",
    " 'night',\n",
    " 'gum',\n",
    " 'sick',\n",
    " 'drawer',\n",
    " 'nose',\n",
    " 'have',\n",
    " 'pretty',\n",
    " 'airplane',\n",
    " 'cry',\n",
    " 'tiger',\n",
    " 'mom',\n",
    " 'talk',\n",
    " 'have',\n",
    " 'green',\n",
    " 'zebra',\n",
    " 'because',\n",
    " 'gum',\n",
    " 'puppy',\n",
    " 'mad',\n",
    " 'wolf',\n",
    " 'donkey',\n",
    " 'yes',\n",
    " 'yucky',\n",
    " 'why',\n",
    " 'no',\n",
    " 'tree',\n",
    " 'tree',\n",
    " 'dryer',\n",
    " 'morning',\n",
    " 'that',\n",
    " 'orange',\n",
    " 'where',\n",
    " 'wolf',\n",
    " 'tomorrow',\n",
    " 'tomorrow',\n",
    " 'gum',\n",
    " 'uncle',\n",
    " 'shower',\n",
    " 'mouth',\n",
    " 'nose',\n",
    " 'farm',\n",
    " 'frog',\n",
    " 'table',\n",
    " 'green',\n",
    " 'another',\n",
    " 'helicopter',\n",
    " 'talk',\n",
    " 'dry',\n",
    " 'hear',\n",
    " 'yourself',\n",
    " 'cute',\n",
    " 'gum',\n",
    " 'garbage',\n",
    " 'dryer',\n",
    " 'find',\n",
    " 'kitty',\n",
    " 'chocolate',\n",
    " 'no',\n",
    " 'bird',\n",
    " 'girl',\n",
    " 'story',\n",
    " 'red',\n",
    " 'cry',\n",
    " 'story',\n",
    " 'yourself',\n",
    " 'vacuum',\n",
    " 'green',\n",
    " 'another']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recordings found: 1\n",
      "sign: hungry, 1/1\n",
      "    pid: 1/21\n",
      "        recording: 1/1\n"
     ]
    }
   ],
   "source": [
    "col_names = pd.read_csv('data/col_names.csv', index_col=0)['0']\n",
    "dataset = pd.DataFrame([],columns=col_names)\n",
    "signs = ['hungry']\n",
    "\n",
    "dataset = update_dataset(dataset,signs,col_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>0</th>\n",
       "      <th>px_0_face</th>\n",
       "      <th>py_0_face</th>\n",
       "      <th>dx_0_face</th>\n",
       "      <th>dy_0_face</th>\n",
       "      <th>px_1_face</th>\n",
       "      <th>py_1_face</th>\n",
       "      <th>dx_1_face</th>\n",
       "      <th>dy_1_face</th>\n",
       "      <th>px_2_face</th>\n",
       "      <th>py_2_face</th>\n",
       "      <th>...</th>\n",
       "      <th>dy_30_pose</th>\n",
       "      <th>px_31_pose</th>\n",
       "      <th>py_31_pose</th>\n",
       "      <th>dx_31_pose</th>\n",
       "      <th>dy_31_pose</th>\n",
       "      <th>px_32_pose</th>\n",
       "      <th>py_32_pose</th>\n",
       "      <th>dx_32_pose</th>\n",
       "      <th>dy_32_pose</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067281</td>\n",
       "      <td>0.548762</td>\n",
       "      <td>0.687274</td>\n",
       "      <td>-0.06768</td>\n",
       "      <td>0.081745</td>\n",
       "      <td>0.545664</td>\n",
       "      <td>0.680934</td>\n",
       "      <td>-0.075489</td>\n",
       "      <td>0.090029</td>\n",
       "      <td>hungry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 2173 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0 px_0_face py_0_face dx_0_face dy_0_face px_1_face py_1_face dx_1_face  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "\n",
       "0 dy_1_face px_2_face py_2_face  ... dy_30_pose px_31_pose py_31_pose  \\\n",
       "0         0         0         0  ...   0.067281   0.548762   0.687274   \n",
       "\n",
       "0 dx_31_pose dy_31_pose px_32_pose py_32_pose dx_32_pose dy_32_pose    sign  \n",
       "0   -0.06768   0.081745   0.545664   0.680934  -0.075489   0.090029  hungry  \n",
       "\n",
       "[1 rows x 2173 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('data/dataset_test_hungry.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>train_landmark_files/25571/1005995721.parquet</td>\n",
       "      <td>25571</td>\n",
       "      <td>1005995721</td>\n",
       "      <td>hungry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              path  participant_id  \\\n",
       "150  train_landmark_files/25571/1005995721.parquet           25571   \n",
       "\n",
       "     sequence_id    sign  \n",
       "150   1005995721  hungry  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.read_csv('data/train.csv')\n",
    "y = y.loc[y.sign=='hungry'].loc[y.participant_id==25571].head(1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dataset(dataset, signs, col_names):\n",
    "    print(f'recordings found: {y.loc[[s in signs for s in y.sign]].shape[0]}')\n",
    "    for i, sign in enumerate(signs):\n",
    "        print(f'sign: {sign}, {i+1}/{len(signs)}')\n",
    "        for j, participant_id in enumerate(y.participant_id.unique()):\n",
    "            print(f'    pid: {j+1}/21')\n",
    "            y_subset = y.loc[(y.sign == sign) & (y.participant_id == participant_id)]\n",
    "            data = []\n",
    "            n = y_subset.shape[0]\n",
    "            for k, path in enumerate(y_subset.path):\n",
    "                print(f'        recording: {k+1}/{n}')\n",
    "                path_D = path\n",
    "                df = pd.read_parquet(path_D)\n",
    "                this_data = []\n",
    "                for type in set(df.type):\n",
    "                    print(type)\n",
    "                    df_t = df.loc[df.type == type]\n",
    "                    for lm_i in set(df_t.landmark_index):\n",
    "                        df_t_i = df_t.loc[(df_t['x'].notna()) & (df_t['y'].notna()) & (df_t.landmark_index == lm_i)]\n",
    "                        if df_t_i.shape[0] != 0:\n",
    "                            this_data.append(df_t_i.iloc[0]['x'])\n",
    "                            this_data.append(df_t_i.iloc[0]['y'])\n",
    "                            this_data.append(df_t_i.iloc[-1]['x'] - df_t_i.iloc[0]['x'])\n",
    "                            this_data.append(df_t_i.iloc[-1]['y'] - df_t_i.iloc[0]['y'])\n",
    "                        else:\n",
    "                            this_data.extend([0,0,0,0])\n",
    "                data.append(this_data + [sign])\n",
    "            sign_df = pd.DataFrame(data, columns=col_names)\n",
    "            dataset = pd.concat((dataset,sign_df), axis=0, ignore_index=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Signs used on round two of data collection\n",
    "['pig',\n",
    " 'elephant',\n",
    " 'mad',\n",
    " 'finger',\n",
    " 'green',\n",
    " 'up',\n",
    " 'bad',\n",
    " 'finger',\n",
    " 'bye',\n",
    " 'airplane',\n",
    " 'mom',\n",
    " 'kitty',\n",
    " 'home',\n",
    " 'yellow',\n",
    " 'shirt',\n",
    " 'talk',\n",
    " 'icecream',\n",
    " 'green',\n",
    " 'clown',\n",
    " 'lion',\n",
    " 'bad',\n",
    " 'thirsty',\n",
    " 'elephant',\n",
    " 'book',\n",
    " 'shirt',\n",
    " 'dog',\n",
    " 'finger',\n",
    " 'pretty',\n",
    " 'vacuum',\n",
    " 'vacuum',\n",
    " 'chocolate',\n",
    " 'pretty',\n",
    " 'same',\n",
    " 'red',\n",
    " 'every',\n",
    " 'feet',\n",
    " 'drawer',\n",
    " 'gum',\n",
    " 'drop',\n",
    " 'story',\n",
    " 'puppy',\n",
    " 'haveto',\n",
    " 'book',\n",
    " 'bad',\n",
    " 'zebra',\n",
    " 'cat',\n",
    " 'cow',\n",
    " 'mad',\n",
    " 'dryer',\n",
    " 'old',\n",
    " 'clown',\n",
    " 'garbage',\n",
    " 'stairs',\n",
    " 'cute',\n",
    " 'wolf',\n",
    " 'for',\n",
    " 'tree',\n",
    " 'stairs',\n",
    " 'sick',\n",
    " 'finish',\n",
    " 'bird',\n",
    " 'nose',\n",
    " 'no',\n",
    " 'drop',\n",
    " 'yellow',\n",
    " 'garbage',\n",
    " 'have',\n",
    " 'blow',\n",
    " 'wet',\n",
    " 'airplane',\n",
    " 'vacuum',\n",
    " 'no',\n",
    " 'bye',\n",
    " 'nose',\n",
    " 'give',\n",
    " 'puppy',\n",
    " 'gum',\n",
    " 'dry',\n",
    " 'shower',\n",
    " 'another',\n",
    " 'every',\n",
    " 'haveto',\n",
    " 'wolf',\n",
    " 'bee',\n",
    " 'empty',\n",
    " 'puppy',\n",
    " 'thirsty',\n",
    " 'night',\n",
    " 'gum',\n",
    " 'sick',\n",
    " 'drawer',\n",
    " 'nose',\n",
    " 'have',\n",
    " 'pretty',\n",
    " 'airplane',\n",
    " 'cry',\n",
    " 'tiger',\n",
    " 'mom',\n",
    " 'talk',\n",
    " 'have',\n",
    " 'green',\n",
    " 'zebra',\n",
    " 'because',\n",
    " 'gum',\n",
    " 'puppy',\n",
    " 'mad',\n",
    " 'wolf',\n",
    " 'donkey',\n",
    " 'yes',\n",
    " 'yucky',\n",
    " 'why',\n",
    " 'no',\n",
    " 'tree',\n",
    " 'tree',\n",
    " 'dryer',\n",
    " 'morning',\n",
    " 'that',\n",
    " 'orange',\n",
    " 'where',\n",
    " 'wolf',\n",
    " 'tomorrow',\n",
    " 'tomorrow',\n",
    " 'gum',\n",
    " 'uncle',\n",
    " 'shower',\n",
    " 'mouth',\n",
    " 'nose',\n",
    " 'farm',\n",
    " 'frog',\n",
    " 'table',\n",
    " 'green',\n",
    " 'another',\n",
    " 'helicopter',\n",
    " 'talk',\n",
    " 'dry',\n",
    " 'hear',\n",
    " 'yourself',\n",
    " 'cute',\n",
    " 'gum',\n",
    " 'garbage',\n",
    " 'dryer',\n",
    " 'find',\n",
    " 'kitty',\n",
    " 'chocolate',\n",
    " 'no',\n",
    " 'bird',\n",
    " 'girl',\n",
    " 'story',\n",
    " 'red',\n",
    " 'cry',\n",
    " 'story',\n",
    " 'yourself',\n",
    " 'vacuum',\n",
    " 'green',\n",
    " 'another']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recordings found: 1\n",
      "sign: hungry, 1/1\n",
      "    pid: 1/21\n",
      "        recording: 1/1\n",
      "left_hand\n",
      "pose\n",
      "face\n",
      "right_hand\n"
     ]
    }
   ],
   "source": [
    "col_names = pd.read_csv('data/col_names.csv', index_col=0)['0']\n",
    "dataset = pd.DataFrame([],columns=col_names)\n",
    "\n",
    "dataset = update_dataset(dataset,signs,col_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
